{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:08.917369Z",
     "start_time": "2024-09-03T17:49:08.877005Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 pH   Temprature        Taste         Odor         Fat     Turbidity       Colour Grade\n",
      "count   1059.000000  1059.000000  1059.000000  1059.000000  1059.000000  1059.000000  1059.000000  1059\n",
      "unique          NaN          NaN          NaN          NaN          NaN          NaN          NaN     3\n",
      "top             NaN          NaN          NaN          NaN          NaN          NaN          NaN   low\n",
      "freq            NaN          NaN          NaN          NaN          NaN          NaN          NaN   429\n",
      "mean       6.630123    44.226629     0.546742     0.432483     0.671388     0.491029   251.840415   NaN\n",
      "std        1.399679    10.098364     0.498046     0.495655     0.469930     0.500156     4.307424   NaN\n",
      "min        3.000000    34.000000     0.000000     0.000000     0.000000     0.000000   240.000000   NaN\n",
      "25%        6.500000    38.000000     0.000000     0.000000     0.000000     0.000000   250.000000   NaN\n",
      "50%        6.700000    41.000000     1.000000     0.000000     1.000000     0.000000   255.000000   NaN\n",
      "75%        6.800000    45.000000     1.000000     1.000000     1.000000     1.000000   255.000000   NaN\n",
      "max        9.500000    90.000000     1.000000     1.000000     1.000000     1.000000   255.000000   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('data/csv/data_milknew.csv')\n",
    "\n",
    "print(df.describe(include='all').to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "828f9469cffe3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:10.281382Z",
     "start_time": "2024-09-03T17:49:10.275330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pH  Temprature  Taste  Odor  Fat   Turbidity  Colour   Grade\n",
      "0  6.6          35      1     0     1          0     254    high\n",
      "1  6.6          36      0     1     0          1     253    high\n",
      "2  8.5          70      1     1     1          1     246     low\n",
      "3  9.5          34      1     1     0          1     255     low\n",
      "4  6.6          37      0     0     0          0     255  medium\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bd0055777c12104",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:11.101873Z",
     "start_time": "2024-09-03T17:49:11.093048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade [high = 0 / low = 1 / medium = 2] :\n",
      "{'Grade': {'high': np.int64(0), 'low': np.int64(1), 'medium': np.int64(2)}}\n",
      "  \n",
      "    pH  Temprature  Taste  Odor  Fat   Turbidity  Colour  Grade\n",
      "0  6.6          35      1     0     1          0     254      0\n",
      "1  6.6          36      0     1     0          1     253      0\n",
      "2  8.5          70      1     1     1          1     246      1\n",
      "3  9.5          34      1     1     0          1     255      1\n",
      "4  6.6          37      0     0     0          0     255      2\n",
      "\n",
      " Grade\n",
      "1    429\n",
      "2    374\n",
      "0    256 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder() \n",
    "\n",
    "print('Grade [high = 0 / low = 1 / medium = 2] :')\n",
    "df[\"Grade\"] = label_encoder.fit_transform(df[\"Grade\"])\n",
    "mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "mapping = {'Grade': mapping}\n",
    "print(mapping)\n",
    "\n",
    "print(\"  \")\n",
    "\n",
    "print(df.head().to_string())\n",
    "\n",
    "# Check class balance\n",
    "print('\\n', df['Grade'].value_counts().to_string(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63a0a7b110100677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:12.104575Z",
     "start_time": "2024-09-03T17:49:12.100584Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28edd52b7d8467d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:13.159961Z",
     "start_time": "2024-09-03T17:49:13.146397Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # Splitting the dataset into features (input) and target (output, label)\n",
    "# X = df.loc[:, df.columns != 'Grade']\n",
    "# y = df['Grade']\n",
    "\n",
    "# # # Classifier training\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33e927de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (848, 7)\n",
      "X_test shape: (211, 7)\n",
      "y_train shape: (848,)\n",
      "y_test shape: (211,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Prepare the data for modeling\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('Grade', axis=1)\n",
    "y = df['Grade']\n",
    "\n",
    "# K-fold cross-validation with stratification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Instantiate the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69a5768aaa777d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:14.290939Z",
     "start_time": "2024-09-03T17:49:14.277348Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc9da3aabfb0275c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:18.539646Z",
     "start_time": "2024-09-03T17:49:15.140101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "_____________________________________________________________ \n",
      "\n",
      "Logistic Regression Best Parameters: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        51\n",
      "           1       0.90      0.71      0.79        86\n",
      "           2       0.68      0.85      0.76        74\n",
      "\n",
      "    accuracy                           0.77       211\n",
      "   macro avg       0.78      0.78      0.77       211\n",
      "weighted avg       0.79      0.77      0.77       211\n",
      "\n",
      "_____________________________________________________________ \n",
      "\n",
      "KNN Best Parameters: {'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "KNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        86\n",
      "           2       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       211\n",
      "   macro avg       1.00      1.00      1.00       211\n",
      "weighted avg       1.00      1.00      1.00       211\n",
      "\n",
      "_____________________________________________________________ \n",
      "\n",
      "SVM Best Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        51\n",
      "           1       1.00      1.00      1.00        86\n",
      "           2       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.97       211\n",
      "   macro avg       0.97      0.96      0.97       211\n",
      "weighted avg       0.97      0.97      0.97       211\n",
      "\n",
      "_____________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision_weighted',\n",
    "    'recall': 'recall_weighted',\n",
    "    'f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "# Create the hyperparameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Create the hyperparameter grid for K-Nearest Neighbors (KNN)\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean\n",
    "}\n",
    "\n",
    "# Create the hyperparameter grid for Support Vector Machine (SVM)\n",
    "param_grid_svm = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Instantiate the models\n",
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV objects for each model\n",
    "grid_search_lr = GridSearchCV(estimator=logreg, param_grid=param_grid_lr, cv=5, n_jobs=-1, \n",
    "                              verbose=2, scoring=scoring, refit='accuracy')\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid_knn, cv=5, n_jobs=-1, \n",
    "                               verbose=2, scoring=scoring, refit='accuracy')\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=svm, param_grid=param_grid_svm, cv=5, n_jobs=-1, \n",
    "                               verbose=2, scoring=scoring, refit='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV objects\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = grid_search_lr.predict(X_test)\n",
    "y_pred_knn = grid_search_knn.predict(X_test)\n",
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "\n",
    "print(\"_____________________________________________________________\", '\\n')\n",
    "# Get and display the best parameters and classification report for each model\n",
    "print('Logistic Regression Best Parameters:', grid_search_lr.best_params_)\n",
    "print('Logistic Regression Classification Report:\\n', classification_report(y_test, y_pred_lr))\n",
    "print(\"_____________________________________________________________\", '\\n')\n",
    "print('KNN Best Parameters:', grid_search_knn.best_params_)\n",
    "print('KNN Classification Report:\\n', classification_report(y_test, y_pred_knn))\n",
    "print(\"_____________________________________________________________\", '\\n')\n",
    "print('SVM Best Parameters:', grid_search_svm.best_params_)\n",
    "print('SVM Classification Report:\\n', classification_report(y_test, y_pred_svm))\n",
    "print(\"_____________________________________________________________\", '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edd3ccdc1757c4f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:49:20.642027Z",
     "start_time": "2024-09-03T17:49:20.630895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best logistic_regression model to 'models/best_logistic_regression.pkl'\n",
      "Saved best knn model to 'models/best_knn.pkl'\n",
      "Saved best svm model to 'models/best_svm.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for saving models\n",
    "import joblib\n",
    "\n",
    "# Dictionary to map the models to their respective GridSearchCV objects\n",
    "models = {\n",
    "    'logistic_regression': grid_search_lr,\n",
    "    'knn': grid_search_knn,\n",
    "    'svm': grid_search_svm\n",
    "}\n",
    "\n",
    "# Loop through the models and save each best model\n",
    "for model_name, grid_search in models.items():\n",
    "    best_model = grid_search.best_estimator_\n",
    "    joblib.dump(best_model, f'models/best_{model_name}.pkl')\n",
    "    joblib.dump(mapping, 'models/mapping.pkl')\n",
    "    joblib.dump(X.columns, 'models/columns.pkl')\n",
    "    print(f\"Saved best {model_name} model to 'models/best_{model_name}.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "130330ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Grade': {'high': np.int64(0), 'low': np.int64(1), 'medium': np.int64(2)}}\n"
     ]
    }
   ],
   "source": [
    "mapping_jl = joblib.load('models/mapping.pkl')\n",
    "\n",
    "# พิมพ์ค่าของ mapping\n",
    "print(mapping_jl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
